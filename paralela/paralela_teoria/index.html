<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Programación Paralela</title>

    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css"
          integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

    <!-- Optional theme -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap-theme.min.css"
          integrity="sha384-fLW2N01lMqjakBkx3l/M9EahuwpSfeNvV63J5ezn3uZzapT0u7EYsXMjQV+0En5r" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="css/starter-template.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>

<body>
      
<nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
                    aria-expanded="false" aria-controls="navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            
        </div>
        <div id="navbar" class="collapse navbar-collapse">
            <ul class="nav navbar-nav">
                <li><a href="#intro">Introducción</a></li>
                <li><a href="#filosofia">Filosofía</a></li>
                <li><a href="#conceptos">Conceptos clave</a></li>
                <li><a href="#ventajas">Ventajas</a></li>
                <li><a href="#modelos">Modelos</a></li>
                <li><a href="#arch">Arquitecturas</a></li>
                <li><a href="#lenguajes">Lenguajes</a></li>
                <li><a href="#biblio">Bibliografía</a></li>
            </ul>
        </div><!--/.nav-collapse -->
    </div>
</nav>

<div class="container">

    <div class="starter-template">
        <h1 id="inicio">Programación Paralela</h1>
    </div>
    <br>

    <div class="row text-center">
        <a href="https://www.flickr.com/photos/32010352@N02/3161625626/">
            <img src="images/3161625626_deae769a7d_z.jpg" class="img-thumbnail">
        </a>
    </div>
    <br>

    <div>
        <h2 id="intro">Introducción</h2>
        <p>La programación paralela es el uso de varios procesadores trabajando en conjunto para dar solución a una tarea en 
            común, lo que hacen es que se dividen el trabajo y cada procesador hace una porción del problema al poder 
            intercambiar datos por una red de interconexión o atraves de memoria.
        </p>
        
    </div>
    <br>
    <div>
        <h2 id="filosofia">Filosofía</h2>
        <h3>¿Que es comoputación paralela?</h3>
        <p>En el sentido más simple, la computación paralela es el uso simultáneo de múltiples recursos computacionales
             para resolver un problema computacional:
        </p>
        <ul>
            <li>
                <p>
                    Un problema se divide en partes discretas que se pueden resolver simultáneamente

                </p>
            </li>

            <li>
                <p>
                    Cada parte se descompone en una serie de instrucciones
                </p>
            </li>
            <li>
                <p>
                    Las instrucciones de cada parte se ejecutan simultáneamente en diferentes procesadores
                </p>
            </li>
            <li>
                <p>
                    Se emplea un mecanismo global de control/coordinación
                </p>
            </li>
        </ul>
        
    </div>
    <br>
    
    <br>
    <div>
        <h2 id="conceptos">Conceptos clave</h2>
        

        <ul>
            <li>
                <p>
                    <b>Tarea:</b>
                    La descomposición de las tareas puede
                    ser una tarea complicada, ya que suelen haber varias formas de descomponer el mismo algoritmo.
                    Definir las tareas para una aplicación apropiadamente es una del trabajo más difícil en el proceso
                    de creación de un programa paralelizable, y difícil de automatizar.

                </p>
            </li>
            
            <li>
                <p>
                    <b>Hilos:</b>
                    Un proceso pesado puede convertirse en varios procesos livianos ejecutados de
                manera concurrente. Cada uno de estos procesos se conoce como hilos. Se comunican entre ellos a través de la memoria global

                </p>
            </li>
            
            <li>
                <p>
                    <b>Granularidad:</b>
                    El tamaño de cada tarea, en término del número de instrucciones. Cada tarea puede tener un tamaño
                    diferente.
                </p>
            </li>
            <li>
                <p>
                    <b>Speedup:</b>
                    Es un proceso para aumentar el rendimiento entre dos sistemas procesando el mismo problema.
                    Es la mejora en la velocidad de ejecución de una tarea ejecutada en dos arquitecturas similares con diferentes recursos.
                </p>
            </li>
            <li>
                <p>
                    <b>Scheduling:</b>
                    Las tareas de una aplicación son asignadas a procesos o hilos, que a su vez son asignados a unidades
                    de procesamiento. El proceso mediante el cual las tareas son asignadas a los procesos o hilos, y se
                    les da un orden de ejecución. Este puede ser especificado en el código, en tiempo de compilación o
                    dinámicamente en tiempo de ejecución. El proceso de scheduling debe tener en cuenta la dependencia
                    entre tareas, ya que, aunque muchas pueden ser independientes, otras pueden requerir los datos
                    producidos por otras tareas.
                </p>
            </li>

            <li>
                <p>
                    <b>Mapping:</b>
                    Es la asignación de procesos e hilos a unidades de procesamiento, procesadores o núcleos.
                    Usualmente el mapping se hace por el sistema en tiempo de ejecución, aunque en ocasiones puede ser
                    influenciado por el programador.

                </p>
            </li>

            <li>
                <p>
                    <b>Sincronización y cooperación:</b>
                    Los programas en paralelo necesitan la sincronización y la coordinación de procesos e hilos, para
                    que haya una ejecución correcta. Los métodos de coordinación y sincronización en la programación
                    paralela están fuertemente asociados a la manera en que los procesos o hilos intercambian
                    información, y esto depende de cómo está organizada la memoria en el hardware.

                </p>
            </li>
            
            
        </ul>
    </div>
    <br>
    <br>
    <div>

        <h2 id="ventajas">Ventajas</h2>

        <ul>

            <li>Resuelve problemas que no se podrían realizar en una sola CPU</li>

            <li>Resuelve problemas que no se pueden resolver en un tiempo razonable</li>

            <li>Permite ejecutar problemas de un orden y complejidad mayor</li>

            <li>Permite ejecutar código de manera más rápida (aceleración)</li>

            <li>Permite ejecutar en general más problemas</li>

            <li>Obtención de resultados en menos tiempo</li>

            <li>Permite la ejecución de varias instrucciones en simultáneo</li>

            <li>Permite dividir una tarea en partes independientes</li>
        </ul>

        <h2>Desventajas</h2>
        <ul>
            <li>Mayor consumo de energía</li>

            <li>Mayor dificultad a la hora de escribir programas</li>

            <li>Dificultad para lograr una buena sincronización y comunicación entre las tareas</li>

            <li>Retardos ocasionados por comunicación ente tareas</li>

            <li>Número de componentes usados es directamente proporcional a los fallos potenciales</li>

            <li>Múltiples procesos se encuentran en condición de carrera si el resultado de los mismos depende del
                    orden de su llegada
                </li>

                <li>Si los procesos que están en condición de carrera no son correctamente sincronizados, puede
                    producirse una corrupción de datos
                </li>
        </ul>
    </div>

    <br>
    
    <div>
        <h2 id="modelos">Modelos de programación paralela</h2>

        <h3>Memoria compartida</h3>

        <ul>
            <li>Los procesos comparten un espacio de memoria común</li>

            <li>Escriben y leen de manera asíncrona</li>

            <li>No es necesario especificar cómo se comunican los datos entre las tareas</li>

            <li>Se usan semáforos o locks para controlar el acceso a la memoria compartida</li>
        </ul>

        

        <h3>Memoria distribuida</h3>

        <ul>

            <li>También llamado modelo de paso de mensajes</li>

            <li>Distintas tareas pueden estar en la misma máquina física y/o a lo largo de cierto</li>

            <li>Las tareas intercambian datos por medio del paso de mensajes</li>

            <li>Enviar y recibir!</li>

        </ul>

        <h3>Hibrido memoria distribuida-comopartida</h3>

        <ul>
            <li>Es la combinación entre memoria compartida y memoria distribuida, con sus ventajas en común.</li>

            <li>Su principal ventaja es su escalabilidad.</li>

            <li>Su principal desventaja es que la complejidad de programación aumenta.
            </li>
        </ul>

    </div>
    <div>
        <h2 id="arch">Arquitectura Multi-procesador</h2>
        
        <h3> Taxonomia de Flynn</h3>

        <ol>
            <li>
                <p>
                    <b>Single Instruction, Single Data (SISD):</b> hay un elemento de procesamiento, que tiene acceso a
                    un
                    único
                    programa y a un almacenamiento de datos. En cada paso, el elemento de procesamiento carga una
                    instrucción y la
                    información correspondiente y ejecuta esta instrucción. El resultado es guardado de vuelta en el
                    almacenamiento
                    de datos. Luego SISD es el computador secuencial convencional, de acuerdo al modelo de von Neumann.
                </p>
                
            </li>

            <li>
                <p>
                    <b>Multiple Instruction, Single Data (MISD):</b> hay múltiples elementos de procesamiento, en el que
                    cada
                    cual tiene memoria privada del programa, pero se tiene acceso común a una memoria global de
                    información.
                    En cada paso, cada elemento de procesamiento de obtiene la misma información de la memoria y carga
                    una
                    instrucción de la memoria privada del programa. Luego, las instrucciones posiblemente diferentes de
                    cada
                    unidad, son ejecutadas en paralelo, usando la información (idéntica) recibida anteriormente. Este
                    modelo
                    es muy restrictivo y no se ha usado en ningún computador de tipo comercial.
                </p>
            </li>

            <li>
                <p>
                    <b>Single Instruction, Multiple Data (SIMD): </b> hay múltiples elementos de procesamiento, en el
                    que
                    cada cual tiene acceso privado a la memoria de información (compartida o distribuida). Sin embargo,
                    hay una sola memoria de programa, desde la cual una unidad de procesamiento especial obtiene y
                    despacha instrucciones. En cada paso, cada unidad de procesamiento obtiene la misma instrucción y
                    carga desde su memoria privada un elemento de información y ejecuta esta instrucción en dicho
                    elemento. Entonces, la instrucción es síncronamente aplicada en paralelo por todos los elementos de
                    proceso a diferentes elementos de información. Para aplicaciones con un grado significante de
                    paralelismo de información, este acercamiento puede ser muy eficiente. Ejemplos pueden ser
                    aplicaciones multimedia y algoritmos de gráficos de computadora.
                </p>
            </li>

            <li>
                <p>
                    <b>Multiple Instruction, Multiple Data (MIMD):</b> hay múltiples unidades de procesamiento, en la
                    cual
                    cada una tiene tanto instrucciones como información separada. Cada elemento ejecuta una instrucción
                    distinta en un elemento de información distinto. Los elementos de proceso trabajan asíncronamente.
                    Los clusters son ejemplo son ejemplos del modelo MIMD.
                </p>
            </li>
        </ol>
    </div>


    <br>
    

    
    <div>
        <h2 id="lenguajes">Principales librerias y frameworks</h2>
        <ul>
            <li><a href="http://bisqwit.iki.fi/story/howto/openmp/">OpenMP</a></li>
                        <li><a href="https://developer.nvidia.com/cuda-zone">CUDA</a></li>
            <li><a href="http://julialang.org/">Julia</a></li>
            <li><a href="https://golang.org/">Go</a></li>
            <li><a href="https://computing.llnl.gov/tutorials/pthreads/">pthreads</a></li>
            
        </ul>
    </div>
    <br>


    <br>
    <div>
        <h2 id="biblio">Bibliografía</h2>
        <ol>
            <li>
                <a href="https://computing.llnl.gov/tutorials/parallel_comp/#Abstract">https://computing.llnl.gov/tutorials/parallel_comp/#Abstract</a>
            </li>
            <li>
                <a href="https://computing.llnl.gov/tutorials/pthreads/">https://computing.llnl.gov/tutorials/pthreads/</a>
            </li>
            <li>
                <a href="http://lahuen.dcc.uchile.cl/mm_wiki/lib/exe/fetch.php?media=cpar:1-modelos.pdf">http://lahuen.dcc.uchile.cl/mm_wiki/lib/exe/fetch.php?media=cpar:1-modelos.pdf</a>
            </li>

            <li>
                <a href="https://computing.llnl.gov/tutorials/openMP/">https://computing.llnl.gov/tutorials/openMP/</a>
            </li>

            <li>
                <a href="http://www.saber.ula.ve/bitstream/123456789/15969/1/com_par.pdf">http://www.saber.ula.ve/bitstream/123456789/15969/1/com_par.pdf</a>
            </li>

            <li>
                <a href="https://en.wikipedia.org/wiki/Parallel_computing">https://en.wikipedia.org/wiki/Parallel_computing</a>
            </li>

            <li>
                <a href="https://www.mcs.anl.gov/~itf/dbpp/text/node9.html">https://www.mcs.anl.gov/~itf/dbpp/text/node9.html</a>
            </li>

            
        </ol>
    </div>

   

    <p>
        Autor: Luis Alejandro Giraldo León
    </p>

</div>

<!-- Bootstrap core JavaScript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"
        integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS"
        crossorigin="anonymous"></script>
</body>
</html>
